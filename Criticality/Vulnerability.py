#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on Fri Jul  7 17:04:03 2017

@author: yan
"""

# vulnerability
# In[]:
get_ipython().magic(u'matplotlib inline')
from matplotlib import pyplot as plt
import networkx as nx
import pandas as pd
import copy
import time
import csv
import os
import sys
from collections import Counter

module_path = os.path.abspath(os.path.join('..'))
if module_path not in sys.path:
    sys.path.append(module_path)

#Modules developed by TU Delft team for thiss project
from network_lib import network_prep as net_p
#from network_lib import network_visualization as net_v
#from network_lib import od_prep as od_p
#from network_lib import weighted_betweenness as betw_w

import geopandas as gp
import numpy as np
from simpledbf import Dbf5
# In[]: Network Preparation
network = r'./input/fiji_south/fj_roads_south_FRA_v4.shp'
centroid = r'./input/fiji_south/OD_south_10Cities.shp'
dbf = Dbf5(r'./input/fiji_south/fj_bridges_south_FRA_v1.dbf')
df_structure = dbf.to_dataframe()
gdf_points, gdf_node_pos, gdf = net_p.prepare_centroids_network(centroid, network)

# Create Networkx MultiGraph object from the GeoDataFrame
G = net_p.gdf_to_simplified_multidigraph(gdf_node_pos, gdf, simplify=False)

# Change the MultiGraph object to Graph object to reduce computation cost
G_tograph = net_p.multigraph_to_graph(G)

# Observe the properties of the Graph object
print('number of disconnected compoents is', nx.number_connected_components(G_tograph))
nx.info(G_tograph)

# Take only the largest subgraph which all connected links
len_old = 0
for g in nx.connected_component_subgraphs(G_tograph):
    if len(list(g.edges())) > len_old:
        G1 = g
        len_old = len(list(g.edges()))
G_sub = G1.copy()

print('number of disconnected compoents is', nx.number_connected_components(G_sub))
nx.info(G_sub)

# Save the simplified transport network back into GeoDataFrame
gdf_sub = net_p.graph_to_df(G_sub)

# assign the OD to the closest node of the biggest subgraph:
gdf_points2, gdf_node_pos2, gdf_new=net_p.prepare_newOD(centroid, gdf_sub)
gdf_points2['population'][6]=30000 # the population of Rakiraki is 29700 at 1996 census, 30000 as approximate   #need to delete
G2_multi = net_p.gdf_to_simplified_multidigraph(gdf_node_pos2, gdf_new, simplify=False)
G2 = net_p.multigraph_to_graph(G2_multi)
gdf2 = net_p.graph_to_df(G2)
allNode = G2.nodes()
allEdge = G2.edges()
od = gdf_points2['Node']

# the output of this section is gdf_points2, gdf_node_pos2, gdf2, G2

# In[]: baseline: find the shortest path for each od pair to minimize the total travel cost;
# output: 1) baseCost ($): total travel cost between all OD pairs; 2) basePath : the shortest path between all OD pairs

n=0
basePath = [[[]for i in range(len(od))] for j in range(len(od))] #for ten cities, i = 10. j = i + 1
baseCost=np.zeros((len(od),len(od)))
for i in range(len(od)):
    for j in range(i+1,len(od)):
        print n
        basePath[i][j]=nx.dijkstra_path(G2,od[i],od[j],weight = 'total_cost') #Total cost = length * unit cost. Unit cost = condition # lis tof nodes
        baseCost[i][j]=nx.dijkstra_path_length(G2,od[i],od[j],weight = 'total_cost') #one number
        n=n+1

# In[]: baseline: find the shortest path for each od to minimize the total travel cost;
# output: 1) baseLength: total travel distance between all OD pairs;
n=0
baseLength=np.zeros((len(od),len(od)))
for i in range(len(od)):
    for j in range(i+1,len(od)):
        print n
        baseLength[i][j]=nx.dijkstra_path_length(G2,od[i],od[j],weight = 'length') #One number
        n=n+1

# In[]:
################### traffic flow matrix ####################################################
k=1.3 #some constant based on existing data
popu={}

for i in range(len(od)): #only OD nodes
    idx = gdf_points2['Node'].tolist().index(od[i])
    popu[od[i]]=gdf_points2['population'].tolist()[idx]

T=np.zeros((len(od),len(od)))  # identical with OD order (e.g. if ten cities, 10x10 array)
for i in range(len(od)):
    for j in range(i+1,len(od)):
        T[i][j]= k*popu[od[i]]*popu[od[j]]/baseLength[i][j]/30*1e3 # AADT (travel per day) Travel gravity model

# In[]: water flood user disruption cost
# assumption: when a structure in the link is being disrupted, the link is disrupted
# this function doesn't consider the repair duration
import copy

def disrupt(r):   # r is return period
#   r='WD_PU_100'    #100 year return period - attribute of the road shapefile. Depth of water in 100yrs return period flood
    #threshold=2
    bridgeRC = 40000*1e-6  #changed to US million dollars per square metre
    culvertRC = 10000*1e-6    #changed to US million dollars per square metre
    crossingRC = 1000*1e-6    #changed to US million dollars per square metre
    roaduserC = 1000  # THIS NEEDS TO BE CHANGE'D
    #WARNING - NO COST FOR ROADS DESTROYED
    stru_damage=[]    # ID of the bridge disrupted in that return period
    link_damage=[]    # OBJECT_ID of the road disrupted in that return period:
    repairC1 = [] # total repair cost in that return period
    repairC2 = []
    repairC3 = []
    repC_link = {}
    test1=[]
    test2=[]
    test3=[]
    #r = 'WD_FU_10'
    G = copy.deepcopy(G2)
    for n in range(len(df_structure)):    #change definition to be road shapefile instead of bridges
        idx = gdf2[gdf2['OBJECT_ID'] == df_structure['LINK_ID'][n]].index.tolist() # find the idx of the row of the gdf2
        if idx!=[]:
            idx=idx[0]
            if df_structure['StructureT'][n]=='Bridge' or df_structure['StructureT'][n]== 'Footbridge':
                if df_structure[r][n]>df_structure['WD_PU_50'][n]:   #edit to add a constant!!!!!! This is bullshit - roads destroyed at different heights of flood!!!!!!   n = row ID in dataframe
                    stru_damage.append(df_structure['OBJECTID'][n])
                    if not(gdf2['OBJECT_ID'][idx] in link_damage):
                        link_damage.append(gdf2['OBJECT_ID'][idx])
                    G[gdf2['FNODE_'][idx]][gdf2['TNODE_'][idx]]['total_cost']=1e10
                    cost = (df_structure[r][n] - df_structure['WD_PU_50'][n])/(df_structure['WD_PU_1000'][n] \
                           - df_structure['WD_PU_50'][n])*1*bridgeRC*float(df_structure['Length'][n])*\
                           float(df_structure['TotalWidth'][n])
                    repairC1.append(cost)
                    test1.append(n)
                    repC_link[gdf2['OBJECT_ID'][idx]] = repC_link.get(gdf2['OBJECT_ID'][idx], 0)+cost

            if df_structure['StructureT'][n]=='Culvert':

                if df_structure[r][n]>df_structure['WD_PU_20'][n]:
                    stru_damage.append(df_structure['OBJECTID'][n])
                    if not(gdf2['OBJECT_ID'][idx] in link_damage):
                        link_damage.append(gdf2['OBJECT_ID'][idx])
                    G[gdf2['FNODE_'][idx]][gdf2['TNODE_'][idx]]['total_cost']=1e10
                    # LOOK - THIS IS THE COST CURVE FOR DISRUPTION. COST IS 0 --> 1 DEPENDING ON FLOOD INTENSITY
                    cost = (df_structure[r][n] - df_structure['WD_PU_20'][n])/(df_structure['WD_PU_1000'][n] \
                           - df_structure['WD_PU_20'][n])*1*culvertRC*float(df_structure['Length'][n])*float(df_structure['TotalWidth'][n])
                    repairC2.append(cost)
                    test2.append(n)
                    repC_link[gdf2['OBJECT_ID'][idx]] = repC_link.get(gdf2['OBJECT_ID'][idx], 0)+cost

            if df_structure['StructureT'][n]=='Crossing':

                if df_structure[r][n]>df_structure['WD_PU_5'][n]:
                    stru_damage.append(df_structure['OBJECTID'][n])
                    if not(gdf2['OBJECT_ID'][idx] in link_damage):
                        link_damage.append(gdf2['OBJECT_ID'][idx])
                    G[gdf2['FNODE_'][idx]][gdf2['TNODE_'][idx]]['total_cost']=1e10
                    l = float(df_structure['Length'][n])
                    if  isnan(l):
                        l=10
                    b = float(df_structure['TotalWidth'][n] )
                    if isnan(b):
                        b=3
                    cost = (df_structure[r][n] - df_structure['WD_PU_5'][n])/(df_structure['WD_PU_1000'][n] \
                           - df_structure['WD_PU_5'][n])*1*crossingRC*l*b
                    repairC3.append(cost)
                    test3.append(n)
                    repC_link[gdf2['OBJECT_ID'][idx]] = repC_link.get(gdf2['OBJECT_ID'][idx], 0)+cost

    to_allNode = []
    for i in range(len(od)):
        to_allNode.append(nx.single_source_dijkstra_path_length(G,od[i],weight = 'total_cost'))

    cost_disrupt= np.zeros((len(od),len(od)))
    for i in range(len(to_allNode)):
        for j in range(len(od)):
            if j>i:
               cost_disrupt[i][j] = to_allNode[i].get(od[j])

    diff = cost_disrupt - baseCost

    # change cost of the isolate OD to zero
    iso = np.zeros((len(od),len(od)))
    for index,item in np.ndenumerate(cost_disrupt):   #index = (i,j) tuple (OD pair). item = value
        if item>=1e9:
            diff[index]=0    #cost of isolated trips / trips not completed
            iso[index]=1

    for i in range(len(to_allNode)):
        disrupt_sumCost = np.sum(np.multiply(diff,T))

    isoTrip_sum= np.sum(np.multiply(iso,T))
    #    print disrupt_sumCost, isoTrip_sum
    reBridge_s = np.sum(repairC1)
    reCulvert_s = np.sum(repairC2)
    reCrossing_s = np.sum(repairC3)
    return disrupt_sumCost, isoTrip_sum,link_damage,stru_damage,repC_link,reBridge_s,reCulvert_s,reCrossing_s,iso
#  disrupt_sumCost:
# In[]: water flood user disruption cost
# expected annual user
disUC=[]

wd = ['WD_PU_5','WD_PU_10','WD_PU_20','WD_PU_50','WD_PU_75','WD_PU_100','WD_PU_200','WD_PU_250','WD_PU_500','WD_PU_1000']
disruptDura=[1,2,3,4,5,6,7,8,9,10] # arbitrary number to show the disruption time
#wd = ['WD_FU_5','WD_FU_10','WD_FU_20','WD_FU_50','WD_FU_75','WD_FU_100','WD_FU_200','WD_FU_250','WD_FU_500','WD_FU_1000']
rpTime = [5, 10, 20, 50, 75, 100, 200, 250, 500, 1000]

for i in range(10):
    disUC.append(disrupt(wd[i]))# total $ value of extra user cost because of disruption

disruptCost = []
isolatTrip = []
repair_bridge =[]
repair_culvert =[]
repair_crossing =[]
num_linkDamage =[]
num_strDamage =[]
for i in range(10):
    disruptCost.append(disUC[i][0])
    isolatTrip.append(disUC[i][1])
    repair_bridge.append(disUC[i][5])
    repair_culvert.append(disUC[i][6])
    repair_crossing.append(disUC[i][7])
    num_linkDamage.append(len(disUC[i][2]))
    num_strDamage.append(len(disUC[i][3]))


##uniq=set(disUC1[2])^set(disUC2[2])
##uimpa=uniq.intersection(link_s)
EAUC=0
EAUL=0
EARB =0
EARCU =0
EARCR =0
for i in range(9):
    EAUC = EAUC + (1.0/rpTime[i]-1.0/rpTime[i+1])*(disUC[i][0]*disruptDura[i]+disUC[i+1][0]*disruptDura[i+1])
    EAUL = EAUL + (1.0/rpTime[i]-1.0/rpTime[i+1])*(disUC[i][1]*disruptDura[i]+disUC[i+1][1]*disruptDura[i])
    EARB = EARB + (1.0/rpTime[i]-1.0/rpTime[i+1])*(disUC[i][5]*disruptDura[i]+disUC[i+1][5]*disruptDura[i+1])
    EARCU = EARCU + (1.0/rpTime[i]-1.0/rpTime[i+1])*(disUC[i][6]*disruptDura[i]+disUC[i+1][6]*disruptDura[i+1])
    EARCR = EARCR + (1.0/rpTime[i]-1.0/rpTime[i+1])*(disUC[i][7]*disruptDura[i]+disUC[i+1][7]*disruptDura[i+1])
EAUC = EAUC/2/1e6
EAUL = EAUL/2/1e6
EARB = EAUL/2
EARCU = EARCU/2
EARCR = EARCR/2
print 'Expected total user disruption cost is $', EAUC, 'million per year'
print 'Expected total isolation trips is',EAUL,'million per year.'
print 'Expected total repair cost for bridge,culvert,and crossing is',EARB,',',EARCU,',',EARCR,'million per year.'

# In[]
# find the expected probability of structure being disrupted:

p_disrS=np.zeros((len(df_structure),2))
for i in range(len(df_structure)): # all links
    for j in range(len(disUC)): # number of return period
        if df_structure['OBJECTID'][i] in disUC[j][3]:
            p_disrS[i,0]=p_disrS[i,0]+1.0/rpTime[j]
            p_disrS[i,1]= df_structure['LINK_ID'][i]
p_disruptedStruc = pd.DataFrame({'Structure_id':df_structure['OBJECTID'].tolist() ,'Type':df_structure['StructureT'].tolist(),'probability':p_disrS[:,0],'Link_id':p_disrS[:,1]})

# In[]
# find the expected probability of link being disrupted:

p_disrL=np.zeros((len(gdf2),2))
for i in range(len(gdf2)): # all links
    for j in range(len(disUC)): # number of return period
        if gdf2['OBJECT_ID'][i] in disUC[j][3]:
            p_disrL[i,1]=p_disrL[i,1]+1.0/rpTime[j]
p_disrL[:,0]= gdf2['OBJECT_ID'].tolist()
p_disruptedLink = pd.DataFrame({'Road_id':p_disrL[:,0],'probability':p_disrL[:,1]})

# In[]
disrC_ann=[] # disruption cost per return period
iso_ann=[] # isolation trips per return period
num_linkdama=[] # number of damage links per return period
num_strdama=[] # number of damage structure per return period
for i in range(1,10):
    disrC_ann.append(disUC[i][0]/1e6)
    iso_ann.append(disUC[i][1]/1e6)
    num_linkdama.append(len(disUC[i][2]))
    num_strdama.append(len(disUC[i][3]))

# In[]: plot number of disruption
x= [10, 20, 50, 75,100, 200, 250, 500, 1000]
#plt.plot(x, disrC_ann, 'ro')
#plt.plot(x, iso_ann, 'ro')
plt.figure()
plt.plot(x, num_linkdama, 'bo-',label = 'number of disrupted links per year')
plt.plot(x, num_strdama, 'ro-',label = 'number of damaged structures per year')
plt.xlabel('return period')
plt.ylabel('Network Performance under disaster')
plt.legend()
plt.show()

# In[]: plot
x= [10, 20, 50, 75, 100, 200, 250, 500, 1000]
repairCost = []
repairB = []
repairCu = []
repairCr = []
for i in range(1,10):
    repairCost.append( disUC[i][5]+disUC[i][6]+disUC[i][7])
    repairB.append(disUC[i][5])
    repairCu.append(disUC[i][6])
    repairCr.append(disUC[i][7])


plt.figure()
#plt.plot(x, repairCost, 'bo-',label = 'annual expected repair cost')
plt.plot(x, repairB, 'bo-',label = 'annual expected bridge repair cost')
plt.plot(x, repairCu, 'ro-',label = 'annual expected culvert repair cost')
plt.plot(x, repairCr, 'go-',label = 'annual expected crossing repair cost')
plt.xlabel('return period')
plt.ylabel('Annual structure Repair Cost (million $)')
plt.legend()
plt.show()
